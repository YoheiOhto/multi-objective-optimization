{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make lookup table from whole row data\n",
    "-----\n",
    "・use pubchempy and CASRN, get need property from PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'for_lookup' from 'prep' (/workspace/HDD1/user/ohto/3-GA/240625_GA_for_TOXPRED/src/prep.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(src_dir)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prep_pubchem_bycas\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m for_lookup\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_load\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_dump\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'for_lookup' from 'prep' (/workspace/HDD1/user/ohto/3-GA/240625_GA_for_TOXPRED/src/prep.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "src_dir = os.path.join(parent_parent_dir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from prep import prep_pubchem_bycas\n",
    "from prep import for_lookup\n",
    "from util import pickle_load\n",
    "from util import pickle_dump\n",
    "from util import robust_z\n",
    "\n",
    "import sqlite3\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pubchempy as pcp\n",
    "import collections\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import robust_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pubchempy for gathering data (canonical smiles, xlogp, and TPSA) for GA\n",
    "# before using pubchempy, gather all CAS-RN in all data \n",
    "\n",
    "cas = []\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        for file_name in [\"for_GA\", \"validation\"]:\n",
    "            df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "            df = df.dropna()\n",
    "            for i in range(len(df)):\n",
    "                cas.append(df.iloc[i,0])\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    for file_name in [\"for_GA\", \"validation\"]:\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "\n",
    "cas = list(set(cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14598/14598 [11:28:15<00:00,  2.83s/it]  \n"
     ]
    }
   ],
   "source": [
    "property = ['CanonicalSMILES', 'XLogP', 'TPSA']\n",
    "all_data = prep_pubchem_bycas(cas, property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = all_data[0].dropna()\n",
    "all_data_na.to_csv(\"../../data/processed/other/all_pubchem_data.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error means all CASRN that cannot get full data from pubchem\n",
    "error = set(all_data[1]) | set(all_cas - all_cas_na)\n",
    "pickle_dump(error, \"../../data/processed/other/all_pubchem_error.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11412/11412 [00:06<00:00, 1895.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# select pubchem data if a CASRN has multiple CIDs\n",
    "all_data_na = all_data_na.reset_index()\n",
    "all_data_na = all_data_na.drop(columns=[\"index\"])\n",
    "\n",
    "all_data_dict = dict()\n",
    "for i in tqdm(range(len(all_data_na))):\n",
    "    cas = all_data_na[\"CAS\"][i]\n",
    "    if cas not in all_data_dict.keys():\n",
    "        all_data_dict[cas] = []\n",
    "        for n in range(len(all_data_na.iloc[i])):\n",
    "            all_data_dict[cas].append(all_data_na.iloc[i,n])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_data_dict, orient='index', columns=[\"CID\",\"CAS\",\"CanonicalSmiles\",\"xlogp\",\"tpsa\"]).reset_index().drop(columns=[\"index\"])\n",
    "df.to_csv(\"../../data/processed/other/all_pubchem_data.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13687/13687 [10:09<00:00, 22.44it/s] \n",
      "100%|██████████| 13687/13687 [36:18<00:00,  6.28it/s] \n"
     ]
    }
   ],
   "source": [
    "lookup_whole = for_lookup(all_data_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(lookup_whole, \"../../data/processed/other/lookup_whole.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6738/6738 [02:26<00:00, 45.88it/s] \n",
      "100%|██████████| 6738/6738 [09:25<00:00, 11.92it/s] \n",
      "100%|██████████| 6754/6754 [02:27<00:00, 45.73it/s] \n",
      "100%|██████████| 6754/6754 [09:25<00:00, 11.93it/s]  \n",
      "100%|██████████| 6704/6704 [02:24<00:00, 46.42it/s] \n",
      "100%|██████████| 6704/6704 [09:11<00:00, 12.16it/s]  \n",
      "100%|██████████| 6761/6761 [02:21<00:00, 47.84it/s] \n",
      "100%|██████████| 6761/6761 [09:25<00:00, 11.95it/s]  \n",
      "100%|██████████| 6770/6770 [02:25<00:00, 46.44it/s] \n",
      "100%|██████████| 6770/6770 [09:45<00:00, 11.55it/s]  \n",
      "100%|██████████| 6771/6771 [02:32<00:00, 44.49it/s] \n",
      "100%|██████████| 6771/6771 [09:22<00:00, 12.04it/s]  \n",
      "100%|██████████| 6767/6767 [02:18<00:00, 48.76it/s] \n",
      "100%|██████████| 6767/6767 [09:14<00:00, 12.20it/s]  \n",
      "100%|██████████| 6769/6769 [02:16<00:00, 49.74it/s] \n",
      "100%|██████████| 6769/6769 [09:14<00:00, 12.20it/s]  \n",
      "100%|██████████| 7046/7046 [02:35<00:00, 45.32it/s] \n",
      "100%|██████████| 7046/7046 [10:45<00:00, 10.91it/s]  \n",
      "100%|██████████| 7049/7049 [02:33<00:00, 45.83it/s] \n",
      "100%|██████████| 7049/7049 [09:54<00:00, 11.85it/s]  \n",
      "100%|██████████| 6755/6755 [02:17<00:00, 48.97it/s] \n",
      "100%|██████████| 6755/6755 [09:09<00:00, 12.30it/s]  \n",
      "100%|██████████| 433/433 [00:00<00:00, 814.05it/s]\n",
      "100%|██████████| 433/433 [00:02<00:00, 214.75it/s]\n",
      "100%|██████████| 431/431 [00:00<00:00, 784.34it/s]\n",
      "100%|██████████| 431/431 [00:02<00:00, 203.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# make for_GA dataset \n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        for file_name in [\"for_GA\"]:\n",
    "            df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "            df = df.dropna()\n",
    "            cas = []\n",
    "            for i in range(len(df)):\n",
    "                cas.append(df.iloc[i,0])\n",
    "            use_data = all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])\n",
    "            lookup = for_lookup(use_data)\n",
    "            pickle_dump(lookup, f\"../../data/processed/{test_num}_{lig}/{file_name}_lookup.pickle\")\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    for file_name in [\"for_GA\"]:\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        cas = []\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "        use_data = all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])\n",
    "        lookup = for_lookup(use_data)\n",
    "        pickle_dump(lookup, f\"../../data/processed/{test_num}/{file_name}_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0901 ago {'50-41-9'}\n",
      "0901 anta {'82640-04-8'}\n",
      "0902 ago {'50-41-9', '57-30-7', '1461-22-9'}\n",
      "0902 anta {'50-41-9', '82640-04-8'}\n",
      "0904 ago set()\n",
      "0904 anta set()\n",
      "0905 ago set()\n",
      "0905 anta set()\n",
      "0701 {'152-11-4', '7789-12-0', '1910-42-5', '73791-47-6', '318-98-9', '10043-35-3', '7447-40-7', '7681-49-4', '1330-20-7', '51-42-3', '614-39-1', '1327-53-3', '76-87-9', '7487-94-7', '7647-14-5', '8007-59-8', '554-13-2', '7784-46-5', '151-50-8', '7446-18-6', '10108-64-2', '7758-99-8', '13410-01-0', '62-76-0', '549-18-8'}\n",
      "0702 {'557-05-1', '7778-80-5', '107-64-2', '25646-77-9', '3926-62-3', '10361-37-2', '1314-13-2', '124-07-02', '917-61-3', '7758-98-7', '866-84-2', '12125-02-9', '7779-90-0'}\n",
      "0907 {'2943-75-1', '84852-15-3'}\n",
      "1001 {'82385-42-0', '10043-35-3', '54-21-7', '147-24-0', '69-57-8', '115-09-3', '7447-41-8'}\n",
      "1002 {'10043-35-3', '147-24-0', '34381-68-5'}\n"
     ]
    }
   ],
   "source": [
    "# if compound in validation dataset cannot make lookup, collect data from text in JACVAM\n",
    "correct_cas = set(all_data_na[\"CAS\"])\n",
    "\n",
    "all_val_error_cas = set()\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "        val_cas = set(val.iloc[:,0])\n",
    "        val_error_cas = val_cas - correct_cas\n",
    "        all_val_error_cas = all_val_error_cas | val_error_cas\n",
    "        print(test_num, lig, val_error_cas)\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "    val_cas = set(val.iloc[:,0])\n",
    "    val_error_cas = val_cas - correct_cas\n",
    "    all_val_error_cas = all_val_error_cas | val_error_cas\n",
    "    print(test_num, val_error_cas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:02<00:00, 15.11it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  8.95it/s]\n",
      "100%|██████████| 86/86 [00:08<00:00,  9.91it/s]\n",
      "100%|██████████| 21/21 [00:05<00:00,  3.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3041.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3055.51it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 3129.02it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 3109.45it/s]\n",
      " 60%|█████▉    | 43/72 [00:32<00:26,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0701 8007-59-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 48/72 [00:35<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0701 1327-53-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 59/72 [00:55<00:25,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0701 1330-20-7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:03<00:00,  1.13it/s]\n",
      "100%|██████████| 56/56 [00:34<00:00,  1.62it/s]\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0907 84852-15-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.25it/s]\n",
      "100%|██████████| 18/18 [00:20<00:00,  1.14s/it]\n",
      "100%|██████████| 16/16 [00:08<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "property = ['CanonicalSMILES', 'XLogP', 'TPSA']\n",
    "\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "        tsv = []\n",
    "        for i in tqdm(range(len(val))):\n",
    "            if val.iloc[i,0] in all_val_error_cas:\n",
    "                time.sleep(2)\n",
    "                data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "                data = data.reset_index()\n",
    "                col = []\n",
    "                col.append(val.iloc[i,0])\n",
    "                col.append(val.iloc[i,1])\n",
    "                try:col.append(data[\"CanonicalSMILES\"][0])\n",
    "                except:col.append(\"###\")\n",
    "                try:col.append(data[\"XLogP\"][0])\n",
    "                except:col.append(\"###\")\n",
    "                try:col.append(data[\"TPSA\"][0])\n",
    "                except:col.append(\"###\")\n",
    "                tsv.append(col)\n",
    "            else:\n",
    "                col = []\n",
    "                col.append(val.iloc[i,0])\n",
    "                col.append(val.iloc[i,1])\n",
    "                for n in range(2, len(all_data_dict[val.iloc[i,0]])):\n",
    "                    col.append(all_data_dict[val.iloc[i,0]][n])\n",
    "                tsv.append(col)\n",
    "        pd.DataFrame(tsv).to_csv(f\"../../data/processed/{test_num}_{lig}/validation_pubchem.tsv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "    tsv = []\n",
    "    for i in tqdm(range(len(val))):\n",
    "        if val.iloc[i,0] in [\"8007-59-8\", \"1327-53-3\", \"1330-20-7\",\"84852-15-3\"]:\n",
    "            print(test_num, val.iloc[i,0])\n",
    "        elif val.iloc[i,0] in all_val_error_cas:\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:col.append(data[\"CanonicalSMILES\"][0])\n",
    "            except:col.append(\"###\")\n",
    "            try:col.append(data[\"XLogP\"][0])\n",
    "            except:col.append(\"###\")\n",
    "            try:col.append(data[\"TPSA\"][0])\n",
    "            except:col.append(\"###\")\n",
    "            tsv.append(col)\n",
    "        else:\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            for n in range(2, len(all_data_dict[val.iloc[i,0]])):\n",
    "                col.append(all_data_dict[val.iloc[i,0]][n])\n",
    "            tsv.append(col)\n",
    "    pd.DataFrame(tsv).to_csv(f\"../../data/processed/{test_num}/validation_pubchem.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace \"###\" in test_name/validation_pubchem.tsv to correct data in Jacvam text\n",
    "\n",
    "## get data about CAS-RN written below from PubChem\n",
    "### 0701 8007-59-8(cas = 7681-52-9, xlogp is from rdkit) 1327-53-3(cas = CAS-1327-53-3, xlogp is from rdkit) 1330-20-7(cas = CAS-1330-20-7, xlogp is from rdkit)\n",
    "### 0907 84852-15-3(cas = CAS-84852-15-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 4097.14it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 1182.87it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 6918.55it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 1974.91it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 4701.77it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 874.29it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 15841.80it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 768.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29683.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10131.17it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 25100.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10158.16it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24898.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9192.54it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 32402.35it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 11168.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "        lookup = for_lookup(val)\n",
    "        pickle_dump(lookup, f\"../../data/processed/{test_num}_{lig}/validation_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 2291.83it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 581.77it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 7139.46it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 1614.08it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 11243.62it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 3742.99it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 15781.24it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 5676.50it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 17938.75it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 6116.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "    lookup = for_lookup(val)\n",
    "    pickle_dump(lookup, f\"../../data/processed/{test_num}/validation_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make cas and severity data only in whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        file_name = \"for_GA\"\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        cas = []\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "        use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "        test_name = test_num + \"_\" + lig\n",
    "        cas_tox = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev.tsv\", sep=\"\\t\", header=None)\n",
    "        cas_tox_use = []\n",
    "        for i in range(len(cas_tox)):\n",
    "            if cas_tox.iloc[i,0] in use_cas:\n",
    "                cas_tox_use.append([cas_tox.iloc[i,0], cas_tox.iloc[i,1]])\n",
    "        pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    file_name = \"for_GA\"\n",
    "    test_name = test_num\n",
    "    df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "    df = df.dropna()\n",
    "    cas = []\n",
    "    for i in range(len(df)):\n",
    "        cas.append(df.iloc[i,0])\n",
    "    use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "    cas_tox = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev.tsv\", sep=\"\\t\", header=None)\n",
    "    cas_tox_use = []\n",
    "    for i in range(len(cas_tox)):\n",
    "        if cas_tox.iloc[i,0] in use_cas:\n",
    "            cas_tox_use.append([cas_tox.iloc[i,0], cas_tox.iloc[i,1]])\n",
    "    pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../data/processed/other/all_pubchem_data.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>CAS</th>\n",
       "      <th>CanonicalSmiles</th>\n",
       "      <th>xlogp</th>\n",
       "      <th>tpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4870</td>\n",
       "      <td>346-18-9</td>\n",
       "      <td>CN1C(NC2=CC(=C(C=C2S1(=O)=O)S(=O)(=O)N)Cl)CSCC...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8430</td>\n",
       "      <td>120-40-1</td>\n",
       "      <td>CCCCCCCCCCCC(=O)N(CCO)CCO</td>\n",
       "      <td>60.8</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33599</td>\n",
       "      <td>68515-49-1</td>\n",
       "      <td>CC(C)CCCCCCCOC(=O)C1=CC=CC=C1C(=O)OCCCCCCCC(C)C</td>\n",
       "      <td>52.6</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5311051</td>\n",
       "      <td>25122-41-2</td>\n",
       "      <td>CC1CC2C3CCC4=CC(=O)C=CC4(C3(C(CC2(C1(C(=O)CCl)...</td>\n",
       "      <td>74.6</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13254</td>\n",
       "      <td>831-82-3</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=C(C=C2)O</td>\n",
       "      <td>29.5</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11407</th>\n",
       "      <td>10334118</td>\n",
       "      <td>697235-49-7</td>\n",
       "      <td>C1=CC=C(C(=C1)C(=O)O)NC(=O)CCC2=CC=C(C=C2)O</td>\n",
       "      <td>86.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11408</th>\n",
       "      <td>22833</td>\n",
       "      <td>6358-64-1</td>\n",
       "      <td>COC1=CC(=C(C=C1N)OC)Cl</td>\n",
       "      <td>44.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11409</th>\n",
       "      <td>17343</td>\n",
       "      <td>2539-17-5</td>\n",
       "      <td>COC1=C(C(=C(C(=C1Cl)Cl)Cl)Cl)O</td>\n",
       "      <td>29.5</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11410</th>\n",
       "      <td>439260</td>\n",
       "      <td>51-41-2</td>\n",
       "      <td>C1=CC(=C(C=C1C(CN)O)O)O</td>\n",
       "      <td>86.7</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11411</th>\n",
       "      <td>3032279</td>\n",
       "      <td>59-58-5</td>\n",
       "      <td>CCCSSC(=C(C)N(CC1=CN=C(N=C1N)C)C=O)CCO</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11412 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CID          CAS  \\\n",
       "0          4870     346-18-9   \n",
       "1          8430     120-40-1   \n",
       "2         33599   68515-49-1   \n",
       "3       5311051   25122-41-2   \n",
       "4         13254     831-82-3   \n",
       "...         ...          ...   \n",
       "11407  10334118  697235-49-7   \n",
       "11408     22833    6358-64-1   \n",
       "11409     17343    2539-17-5   \n",
       "11410    439260      51-41-2   \n",
       "11411   3032279      59-58-5   \n",
       "\n",
       "                                         CanonicalSmiles  xlogp  tpsa  \n",
       "0      CN1C(NC2=CC(=C(C=C2S1(=O)=O)S(=O)(=O)N)Cl)CSCC...  152.0   2.6  \n",
       "1                              CCCCCCCCCCCC(=O)N(CCO)CCO   60.8   3.5  \n",
       "2        CC(C)CCCCCCCOC(=O)C1=CC=CC=C1C(=O)OCCCCCCCC(C)C   52.6  10.6  \n",
       "3      CC1CC2C3CCC4=CC(=O)C=CC4(C3(C(CC2(C1(C(=O)CCl)...   74.6   2.5  \n",
       "4                           C1=CC=C(C=C1)OC2=CC=C(C=C2)O   29.5   3.4  \n",
       "...                                                  ...    ...   ...  \n",
       "11407        C1=CC=C(C(=C1)C(=O)O)NC(=O)CCC2=CC=C(C=C2)O   86.6   3.4  \n",
       "11408                             COC1=CC(=C(C=C1N)OC)Cl   44.5   1.8  \n",
       "11409                     COC1=C(C(=C(C(=C1Cl)Cl)Cl)Cl)O   29.5   4.4  \n",
       "11410                            C1=CC(=C(C=C1C(CN)O)O)O   86.7  -1.2  \n",
       "11411             CCCSSC(=C(C)N(CC1=CN=C(N=C1N)C)C=O)CCO  143.0   1.1  \n",
       "\n",
       "[11412 rows x 5 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7046 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7046/7046 [35:39<00:00,  3.29it/s]  \n",
      "100%|██████████| 7049/7049 [35:20<00:00,  3.32it/s]  \n",
      "100%|██████████| 6755/6755 [34:00<00:00,  3.31it/s] \n",
      "100%|██████████| 433/433 [02:11<00:00,  3.29it/s]\n",
      "100%|██████████| 431/431 [02:12<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    test_name = test_num\n",
    "    cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "    smiles = []\n",
    "    for i in tqdm(range(len(cas_tox_use))):\n",
    "        for n in range(len(df)):\n",
    "            if cas_tox_use.iloc[i,0] == df.iloc[n,1]:\n",
    "                smiles.append(df.iloc[n,2])\n",
    "                break\n",
    "    cas_tox_use.loc[:,3] = smiles\n",
    "    pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        test_name = test_num + \"_\" + lig\n",
    "        cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "        smiles = []\n",
    "        for i in range(len(cas_tox_use)):\n",
    "            for n in range(len(df)):\n",
    "                if cas_tox_use.iloc[i,0] == df.iloc[n,1]:\n",
    "                    smiles.append(df.iloc[n,2])\n",
    "        cas_tox_use.loc[:,3] = smiles\n",
    "        pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
